# algo-bot
Hybrid AI-Powered Crypto Trading Bot on Binance

Engineered and backtested a sophisticated algorithmic trading bot leveraging a dual-stage AI approach with a LightGBM classifier for volatility prediction and a Proximal Policy Optimization (PPO) reinforcement learning agent for trade execution. Evaluated on 20 days of 1-minute Solana (SOLUSDT) historical data (approximately 28,800 data points), the LightGBM model achieved a 54% accuracy in predicting significant price movements, with an AUC of 0.51. The subsequent RL agent, trained on these predictions and a rich set of technical indicators, demonstrated a foundational strategy in backtesting, resulting in a -0.65% P/L. This project highlights the potential of combining predictive ML with adaptive RL for nuanced financial market navigation, identifying LGBM-derived volatility probabilities as a key input for the RL decision-making process.

Algorithmic Trading Bot with Machine Learning and Reinforcement Learning
This project is a sophisticated algorithmic trading bot designed for cryptocurrency markets, specifically using the Binance API. It employs a hybrid strategy that combines a LightGBM (LGBM) classifier with a Proximal Policy Optimization (PPO) reinforcement learning (RL) agent to make trading decisions.

Overview
The core strategy is a two-step decision-making process:

Prediction Model (LGBM): A supervised machine learning model is first trained to predict the probability of a significant price movement occurring within a short future timeframe.

Decision Model (RL Agent): A reinforcement learning agent is then trained to take the optimal action (Buy, Sell, or Hold). The agent's "view" of the market includes not only traditional technical indicators but also the predictions from the LGBM model, allowing it to make more informed decisions.

The framework is built to be modular, enabling independent training, backtesting, and live/simulated trading sessions.

How It Works
1. Data Processing and Feature Engineering
The bot begins by fetching historical 1-minute k-line (candlestick) data for a specified cryptocurrency pair (e.g., SOLUSDT). It then calculates a comprehensive set of technical indicators and features from this data, including:

Standard Indicators: RSI, PSAR, ATR, Bollinger Bands, and Stochastic Oscillator.

Moving Averages: Fast, Medium, and Slow SMAs.

Derived Features: Flags for RSI being oversold/overbought, price crossing the PSAR, and lagged indicator values.

2. The LGBM Classifier
The LightGBM model is trained as a binary classifier. Its primary goal is not to predict the direction (up or down) but to predict the volatility.

Target: The model is trained to predict whether the price will move by a certain percentage (LGBM_SIGNIFICANT_CHANGE_THRESHOLD) within the next few minutes (LGBM_LOOKAHEAD_BARS).

Output: For any given moment, the model outputs two probabilities: P(No Significant Move) and P(Significant Move).

3. The PPO Reinforcement Learning Agent
The RL agent is the final decision-maker. It is trained using the PPO algorithm from the Stable Baselines3 library in a custom trading environment.

Observation Space (The Agent's View): The state provided to the agent at each step includes:

All the calculated technical indicators.

Current portfolio status (e.g., position held, unrealized profit/loss).

The two probabilities generated by the LGBM model.

Action Space: The agent can choose one of three actions: Hold, Buy, or Sell.

Reward System: The agent is rewarded for making profitable trades and penalized for losses, encouraging it to develop a profitable strategy over time.

4. Backtesting and Live Trading
Backtesting: The framework includes a robust backtesting engine that simulates the hybrid model's performance on historical data. It generates a detailed plot showing portfolio value over time, asset price, and the buy/sell signals executed by the bot.

Live/Simulation: The bot can be run in a live trading mode (if API keys are provided) or a "pure simulation" mode that uses historical data and generates synthetic ticks to test the bot's logic in a forward-testing manner without risk.

How to Use
The main execution block at the end of the notebook (if __name__ == '__main__':) provides simple boolean flags to control the bot's operation:

if __name__ == '__main__':
    TRAIN_LGBM = True      # Set to True to train a new LGBM model
    TRAIN_RL = True        # Set to True to train a new RL agent
    RUN_BACKTEST = True    # Set to True to run a backtest on historical data
    RUN_LIVE = False       # Set to True to run the bot in live/simulation mode

Configuration: Fill in your Binance API keys in the configuration section if you intend to run it against the live or testnet markets.

Training: Set TRAIN_LGBM and TRAIN_RL to True to train the models from scratch using the latest data. The trained models (lgbm_enhanced_predictor.pkl, rl_agent_enhanced_lgbm.zip) will be saved locally.

Backtesting: After training, set RUN_BACKTEST to True to evaluate the performance of the newly trained models.

Live Trading: Set RUN_LIVE to True to start the live trading loop. Ensure models have been trained or are present in the local directory.

Error Note
The live trading loop in the provided notebook file encounters a ValueError. This is due to an incorrect conditional check on a NumPy array. To fix this, the line:

if not rl_base_names:

in the run_live_ml_bot function should be changed to:

if rl_base_names.size == 0:

This correctly checks if the feature list for the RL model is empty.
